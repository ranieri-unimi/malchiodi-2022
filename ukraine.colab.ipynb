{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranieri-unimi/malchiodi-2022/blob/main/ukraine.colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqGrV6XdWKCI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgQoZYRAWKCK"
      },
      "source": [
        "once"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ],
      "metadata": {
        "id": "2uhwYor6WVuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import findspark"
      ],
      "metadata": {
        "id": "NrOTb9eEWSpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mH3gc9TWKCM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_USERNAME\"] = 'ranieriunimi'\n",
        "os.environ[\"KAGGLE_KEY\"] = str(hex(232307088475198570779809482024044346960))[2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngXoXE4KWKCN"
      },
      "outputs": [],
      "source": [
        "ref = 'bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows'\n",
        "!mkdir datasets\n",
        "!kaggle datasets download $ref --unzip -p ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Q8HxqkWKCN"
      },
      "source": [
        "from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoA9_EouWKCO"
      },
      "outputs": [],
      "source": [
        "filename = r\"./datasets/UkraineCombinedTweetsDeduped20220227-131611.csv.gzip\"\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.read_csv(filename, compression='gzip', index_col=0, encoding='utf-8', quoting=csv.QUOTE_ALL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABxWwFYYWKCP"
      },
      "outputs": [],
      "source": [
        "#lang_hist = {l:df[df.language == l].size for l in df.language.unique()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_frlylt5WKCP"
      },
      "outputs": [],
      "source": [
        "datalist = df[df.language == 'en'].text.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIzYGa4CWKCQ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kywqu11WKCQ"
      },
      "outputs": [],
      "source": [
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i9KWOCjWKCR"
      },
      "outputs": [],
      "source": [
        "# https://www.pluralsight.com/guides/building-a-twitter-sentiment-analysis-in-python\n",
        "\n",
        "def preprocess_tweet_text(tweet):\n",
        "    index, tweet = tweet\n",
        "\n",
        "    tweet.lower()\n",
        "\n",
        "    # Remove urls\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove user @ references and '#' from tweet\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
        "\n",
        "    # Remove punctuations\n",
        "    # tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    tweet = tweet.translate(str.maketrans(string.punctuation+'â€¦', ' '*(len(string.punctuation)+1)))  # puntctuation to spaces\n",
        "\n",
        "    # Remove stopwords\n",
        "    tweet_tokens = word_tokenize(tweet)\n",
        "    filtered_words = [w for w in tweet_tokens if not w in set(stopwords.words('english'))]\n",
        "    \n",
        "    ps = PorterStemmer()\n",
        "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]\n",
        "    \n",
        "    return (index, lemma_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REaNAuF2WKCS"
      },
      "source": [
        "hadoooooop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gMPGu1YWKCS"
      },
      "outputs": [],
      "source": [
        "# import findspark\n",
        "# findspark.init(\"spark-3.1.1-bin-hadoop3.2\") # SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sc.parallelize(enumerate(datalist)).map(preprocess_tweet_text)"
      ],
      "metadata": {
        "id": "Jlra5dFu_suL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing = dataset.flatMap(lambda _, v : [(e,e) for e in v]).reduceByKey(lambda k, v : k)"
      ],
      "metadata": {
        "id": "qweNpiR__zu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triples = dataset.flatMap(lambda p: [( (p[0], i), t) for i, t in enumerate(p[1])])"
      ],
      "metadata": {
        "id": "XISFlZcshj9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triples.take(10)"
      ],
      "metadata": {
        "id": "4xAMhdn25EEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### counts D1"
      ],
      "metadata": {
        "id": "fvv0WIpO-Tma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firstPass = triples.map(lambda k, v : (v,1)).reduceByKey(lambda a,b: a+b)"
      ],
      "metadata": {
        "id": "5AEj-vs6B1aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firstPass.take(7)"
      ],
      "metadata": {
        "id": "XA_YJNeXCeG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e2cd697ea1a65fb50dbc24e0f8485a2ca518dbc7d7a135f655e94e4f59b8539e"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "ukraine.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}